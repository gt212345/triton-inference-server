#
# Multistage build.
#
FROM --platform=$BUILDPLATFORM continuumio/miniconda3 AS conda-build

ARG PYTHONNOUSERSITE=True

RUN conda create --name triton-conda-env python=3.8 scikit-learn pytorch==1.11.0 torchvision==0.12.0 -c conda-forge -c pytorch

# Install triton_python_model
ARG TRITON_PYTHON_MODEL_VERSION
ADD /triton_python_model /tmp/triton_python_model
ADD requirements.txt /tmp/
ADD setup.py /tmp/
RUN conda run -n triton-conda-env \
  python -m pip install -r /tmp/requirements.txt
RUN conda run -n triton-conda-env \
  python -m pip install --no-deps /tmp
RUN cd /tmp && conda run -n triton-conda-env \
  python setup.py install

# Install conda-pack
RUN conda install conda-pack=0.7.0 -c conda-forge

#  conda pack
RUN conda pack -n triton-conda-env -o python-3-8.tar.gz



ARG TRITON_VERSION=2.29.0
ARG TRITON_CONTAINER_VERSION=22.12

FROM nvcr.io/nvidia/tritonserver:22.12-py3 AS full

ENV DEBIAN_FRONTEND=noninteractive

RUN apt-get update && apt-get install -y --no-install-recommends autoconf rapidjson-dev libz-dev && \
        apt-get clean && rm -rf /var/lib/apt/lists/*
RUN pip3 install cmake==3.24.3

# backend build
RUN mkdir -p /workspace/build
WORKDIR /workspace/build
RUN git clone https://github.com/triton-inference-server/fastertransformer_backend
RUN mkdir -p /workspace/build/fastertransformer_backend/build

WORKDIR /workspace/build/fastertransformer_backend/build
ARG FORCE_BACKEND_REBUILD=0
RUN cmake \
      -D CMAKE_EXPORT_COMPILE_COMMANDS=1 \
      -D CMAKE_BUILD_TYPE=Release \
      -D CMAKE_INSTALL_PREFIX=/opt/tritonserver \
      -D TRITON_COMMON_REPO_TAG="r${NVIDIA_TRITON_SERVER_VERSION}" \
      -D TRITON_CORE_REPO_TAG="r${NVIDIA_TRITON_SERVER_VERSION}" \
      -D TRITON_BACKEND_REPO_TAG="r${NVIDIA_TRITON_SERVER_VERSION}" \
      ..
RUN make -j"$(grep -c ^processor /proc/cpuinfo)" install



FROM nvcr.io/nvidia/tritonserver:22.12-py3-min


ENV PATH /opt/tritonserver/bin:${PATH}

ENV LD_LIBRARY_PATH /opt/tritonserver/backends/onnxruntime:${LD_LIBRARY_PATH}

ENV TRITON_SERVER_GPU_ENABLED    1

# Ensure apt-get won't prompt for selecting options
ENV DEBIAN_FRONTEND=noninteractive

# Common dependencies.
RUN apt-get update &&     apt-get install -y --no-install-recommends             software-properties-common             libb64-0d             libcurl4-openssl-dev             libre2-5             git             gperf             dirmngr             libgoogle-perftools-dev             libnuma-dev             curl             libgomp1    python3      libarchive-dev             python3-pip             libpython3-dev &&     rm -rf /var/lib/apt/lists/*

ENV DCGM_VERSION 2.2.9
RUN curl -o /tmp/cuda-keyring.deb     https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/cuda-keyring_1.0-1_all.deb     && apt install /tmp/cuda-keyring.deb && rm /tmp/cuda-keyring.deb &&     apt-get update && apt-get install -y datacenter-gpu-manager=1:2.2.9

# Extra defensive wiring for CUDA Compat lib
RUN ln -sf ${_CUDA_COMPAT_PATH}/lib.real ${_CUDA_COMPAT_PATH}/lib  && echo ${_CUDA_COMPAT_PATH}/lib > /etc/ld.so.conf.d/00-cuda-compat.conf  && ldconfig  && rm -f ${_CUDA_COMPAT_PATH}/lib


WORKDIR /opt/tritonserver
RUN rm -fr /opt/tritonserver/*
# COPY docker/entrypoint.d/ /opt/nvidia/entrypoint.d/

WORKDIR /opt/tritonserver
COPY --from=full /opt/tritonserver/LICENSE .
COPY --from=full /opt/tritonserver/TRITON_VERSION .
COPY --from=full /opt/tritonserver/NVIDIA_Deep_Learning_Container_License.pdf .
COPY --from=full /opt/tritonserver/bin bin/
COPY --from=full /opt/tritonserver/lib lib/
COPY --from=full /opt/tritonserver/include include/
# Copying over backends 
COPY --from=full /opt/tritonserver/backends/pytorch /opt/tritonserver/backends/pytorch
COPY --from=full /opt/tritonserver/backends/tensorflow1 /opt/tritonserver/backends/tensorflow1
COPY --from=full /opt/tritonserver/backends/tensorflow2 /opt/tritonserver/backends/tensorflow2
COPY --from=full /opt/tritonserver/backends/onnxruntime /opt/tritonserver/backends/onnxruntime
COPY --from=full /opt/tritonserver/backends/python /opt/tritonserver/backends/python
COPY --from=full /opt/tritonserver/backends/tensorrt /opt/tritonserver/backends/tensorrt
COPY --from=full /opt/tritonserver/backends/fastertransformer /opt/tritonserver/backends/fastertransformer
# Copying over repoagents 
COPY --from=full /opt/tritonserver/repoagents/checksum /opt/tritonserver/repoagents/checksuml
COPY --from=full /usr/bin/serve /usr/bin/.
# Copying over conda-env
WORKDIR /conda-pack
COPY --from=conda-build /python-3-8.tar.gz ./

ENV NCCL_LAUNCH_MODE=GROUP
